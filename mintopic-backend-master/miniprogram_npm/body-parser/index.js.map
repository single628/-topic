{"version":3,"sources":["index.js","lib/types/json.js","lib/read.js","lib/types/raw.js","lib/types/text.js","lib/types/urlencoded.js"],"names":[],"mappings":";;;;;;;AAAA;AACA;AACA;AACA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA,AENA;AHUA,AENA,ADGA,AENA;AHUA,AENA,ADGA,AENA;AHUA,AENA,ADGA,AENA,ACHA;AJaA,AENA,ADGA,AENA,ACHA;AJaA,AENA,ADGA,AENA,ACHA;AJaA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AENA,ACHA,ACHA;ALgBA,AENA,ADGA,AGTA,ACHA;ALgBA,AENA,ADGA,AGTA,ACHA;ALgBA,AENA,ADGA,AGTA,ACHA;ALgBA,AENA,ADGA,AGTA,ACHA;ALgBA,AENA,ADGA,AGTA,ACHA;ALgBA,AENA,ADGA,AGTA,ACHA;ALgBA,AENA,ADGA,AGTA,ACHA;ALgBA,AENA,ADGA,AGTA,ACHA;ALgBA,AENA,ADGA,AGTA,ACHA;ALgBA,AENA,ADGA,AGTA,ACHA;ALgBA,AENA,ADGA,AGTA,ACHA;ALgBA,AENA,ADGA,AGTA,ACHA;ALgBA,AENA,ADGA,AGTA,ACHA;ALgBA,AENA,ADGA,AGTA,ACHA;ALgBA,AENA,ADGA,AGTA,ACHA;ALgBA,AENA,ADGA,AGTA,ACHA;ALgBA,AENA,ADGA,AGTA,ACHA;ALgBA,AENA,ADGA,AGTA,ACHA;ALgBA,AENA,ADGA,AGTA,ACHA;ALgBA,AENA,ADGA,AGTA,ACHA;ALgBA,AENA,ADGA,AGTA,ACHA;ALgBA,AENA,ADGA,AGTA,ACHA;ALgBA,AENA,ADGA,AGTA,ACHA;ALgBA,AENA,ADGA,AIZA;ALgBA,AENA,ADGA,AIZA;ALgBA,AENA,ADGA,AIZA;ALgBA,AENA,ADGA,AIZA;ALgBA,AENA,ADGA,AIZA;ALgBA,AENA,ADGA,AIZA;ALgBA,AENA,ADGA,AIZA;ALgBA,AENA,ADGA,AIZA;ALgBA,AENA,ADGA,AIZA;ALgBA,AENA,ADGA,AIZA;ALgBA,AENA,ADGA,AIZA;ALgBA,AENA,ADGA,AIZA;ALgBA,AENA,ADGA,AIZA;ALgBA,AENA,ADGA,AIZA;ALgBA,AENA,ADGA,AIZA;ALgBA,AENA,ADGA,AIZA;ALgBA,AENA,ADGA,AIZA;ALgBA,AENA,ADGA,AIZA;ALgBA,AENA,ADGA,AIZA;ALgBA,AENA,ADGA,AIZA;ALgBA,AENA,ADGA,AIZA;ALgBA,AENA,ADGA,AIZA;ALgBA,AENA,ADGA,AIZA;ALgBA,AENA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","file":"index.js","sourcesContent":["/*!\n * body-parser\n * Copyright(c) 2014-2015 Douglas Christopher Wilson\n * MIT Licensed\n */\n\n\n\n/**\n * Module dependencies.\n * @private\n */\n\nvar deprecate = require('depd')('body-parser')\n\n/**\n * Cache of loaded parsers.\n * @private\n */\n\nvar parsers = Object.create(null)\n\n/**\n * @typedef Parsers\n * @type {function}\n * @property {function} json\n * @property {function} raw\n * @property {function} text\n * @property {function} urlencoded\n */\n\n/**\n * Module exports.\n * @type {Parsers}\n */\n\nexports = module.exports = deprecate.function(bodyParser,\n  'bodyParser: use individual json/urlencoded middlewares')\n\n/**\n * JSON parser.\n * @public\n */\n\nObject.defineProperty(exports, 'json', {\n  configurable: true,\n  enumerable: true,\n  get: createParserGetter('json')\n})\n\n/**\n * Raw parser.\n * @public\n */\n\nObject.defineProperty(exports, 'raw', {\n  configurable: true,\n  enumerable: true,\n  get: createParserGetter('raw')\n})\n\n/**\n * Text parser.\n * @public\n */\n\nObject.defineProperty(exports, 'text', {\n  configurable: true,\n  enumerable: true,\n  get: createParserGetter('text')\n})\n\n/**\n * URL-encoded parser.\n * @public\n */\n\nObject.defineProperty(exports, 'urlencoded', {\n  configurable: true,\n  enumerable: true,\n  get: createParserGetter('urlencoded')\n})\n\n/**\n * Create a middleware to parse json and urlencoded bodies.\n *\n * @param {object} [options]\n * @return {function}\n * @deprecated\n * @public\n */\n\nfunction bodyParser (options) {\n  var opts = {}\n\n  // exclude type option\n  if (options) {\n    for (var prop in options) {\n      if (prop !== 'type') {\n        opts[prop] = options[prop]\n      }\n    }\n  }\n\n  var _urlencoded = exports.urlencoded(opts)\n  var _json = exports.json(opts)\n\n  return function bodyParser (req, res, next) {\n    _json(req, res, function (err) {\n      if (err) return next(err)\n      _urlencoded(req, res, next)\n    })\n  }\n}\n\n/**\n * Create a getter for loading a parser.\n * @private\n */\n\nfunction createParserGetter (name) {\n  return function get () {\n    return loadParser(name)\n  }\n}\n\n/**\n * Load a parser module.\n * @private\n */\n\nfunction loadParser (parserName) {\n  var parser = parsers[parserName]\n\n  if (parser !== undefined) {\n    return parser\n  }\n\n  // this uses a switch for static require analysis\n  switch (parserName) {\n    case 'json':\n      parser = require('./lib/types/json')\n      break\n    case 'raw':\n      parser = require('./lib/types/raw')\n      break\n    case 'text':\n      parser = require('./lib/types/text')\n      break\n    case 'urlencoded':\n      parser = require('./lib/types/urlencoded')\n      break\n  }\n\n  // store to prevent invoking require()\n  return (parsers[parserName] = parser)\n}\n","/*!\n * body-parser\n * Copyright(c) 2014 Jonathan Ong\n * Copyright(c) 2014-2015 Douglas Christopher Wilson\n * MIT Licensed\n */\n\n\n\n/**\n * Module dependencies.\n * @private\n */\n\nvar bytes = require('bytes')\nvar contentType = require('content-type')\nvar createError = require('http-errors')\nvar debug = require('debug')('body-parser:json')\nvar read = require('../read')\nvar typeis = require('type-is')\n\n/**\n * Module exports.\n */\n\nmodule.exports = json\n\n/**\n * RegExp to match the first non-space in a string.\n *\n * Allowed whitespace is defined in RFC 7159:\n *\n *    ws = *(\n *            %x20 /              ; Space\n *            %x09 /              ; Horizontal tab\n *            %x0A /              ; Line feed or New line\n *            %x0D )              ; Carriage return\n */\n\nvar FIRST_CHAR_REGEXP = /^[\\x20\\x09\\x0a\\x0d]*(.)/ // eslint-disable-line no-control-regex\n\n/**\n * Create a middleware to parse JSON bodies.\n *\n * @param {object} [options]\n * @return {function}\n * @public\n */\n\nfunction json (options) {\n  var opts = options || {}\n\n  var limit = typeof opts.limit !== 'number'\n    ? bytes.parse(opts.limit || '100kb')\n    : opts.limit\n  var inflate = opts.inflate !== false\n  var reviver = opts.reviver\n  var strict = opts.strict !== false\n  var type = opts.type || 'application/json'\n  var verify = opts.verify || false\n\n  if (verify !== false && typeof verify !== 'function') {\n    throw new TypeError('option verify must be function')\n  }\n\n  // create the appropriate type checking function\n  var shouldParse = typeof type !== 'function'\n    ? typeChecker(type)\n    : type\n\n  function parse (body) {\n    if (body.length === 0) {\n      // special-case empty json body, as it's a common client-side mistake\n      // TODO: maybe make this configurable or part of \"strict\" option\n      return {}\n    }\n\n    if (strict) {\n      var first = firstchar(body)\n\n      if (first !== '{' && first !== '[') {\n        debug('strict violation')\n        throw createStrictSyntaxError(body, first)\n      }\n    }\n\n    try {\n      debug('parse json')\n      return JSON.parse(body, reviver)\n    } catch (e) {\n      throw normalizeJsonSyntaxError(e, {\n        message: e.message,\n        stack: e.stack\n      })\n    }\n  }\n\n  return function jsonParser (req, res, next) {\n    if (req._body) {\n      debug('body already parsed')\n      next()\n      return\n    }\n\n    req.body = req.body || {}\n\n    // skip requests without bodies\n    if (!typeis.hasBody(req)) {\n      debug('skip empty body')\n      next()\n      return\n    }\n\n    debug('content-type %j', req.headers['content-type'])\n\n    // determine if request should be parsed\n    if (!shouldParse(req)) {\n      debug('skip parsing')\n      next()\n      return\n    }\n\n    // assert charset per RFC 7159 sec 8.1\n    var charset = getCharset(req) || 'utf-8'\n    if (charset.substr(0, 4) !== 'utf-') {\n      debug('invalid charset')\n      next(createError(415, 'unsupported charset \"' + charset.toUpperCase() + '\"', {\n        charset: charset,\n        type: 'charset.unsupported'\n      }))\n      return\n    }\n\n    // read\n    read(req, res, next, parse, debug, {\n      encoding: charset,\n      inflate: inflate,\n      limit: limit,\n      verify: verify\n    })\n  }\n}\n\n/**\n * Create strict violation syntax error matching native error.\n *\n * @param {string} str\n * @param {string} char\n * @return {Error}\n * @private\n */\n\nfunction createStrictSyntaxError (str, char) {\n  var index = str.indexOf(char)\n  var partial = str.substring(0, index) + '#'\n\n  try {\n    JSON.parse(partial); /* istanbul ignore next */ throw new SyntaxError('strict violation')\n  } catch (e) {\n    return normalizeJsonSyntaxError(e, {\n      message: e.message.replace('#', char),\n      stack: e.stack\n    })\n  }\n}\n\n/**\n * Get the first non-whitespace character in a string.\n *\n * @param {string} str\n * @return {function}\n * @private\n */\n\nfunction firstchar (str) {\n  return FIRST_CHAR_REGEXP.exec(str)[1]\n}\n\n/**\n * Get the charset of a request.\n *\n * @param {object} req\n * @api private\n */\n\nfunction getCharset (req) {\n  try {\n    return (contentType.parse(req).parameters.charset || '').toLowerCase()\n  } catch (e) {\n    return undefined\n  }\n}\n\n/**\n * Normalize a SyntaxError for JSON.parse.\n *\n * @param {SyntaxError} error\n * @param {object} obj\n * @return {SyntaxError}\n */\n\nfunction normalizeJsonSyntaxError (error, obj) {\n  var keys = Object.getOwnPropertyNames(error)\n\n  for (var i = 0; i < keys.length; i++) {\n    var key = keys[i]\n    if (key !== 'stack' && key !== 'message') {\n      delete error[key]\n    }\n  }\n\n  // replace stack before message for Node.js 0.10 and below\n  error.stack = obj.stack.replace(error.message, obj.message)\n  error.message = obj.message\n\n  return error\n}\n\n/**\n * Get the simple type checker.\n *\n * @param {string} type\n * @return {function}\n */\n\nfunction typeChecker (type) {\n  return function checkType (req) {\n    return Boolean(typeis(req, type))\n  }\n}\n","/*!\n * body-parser\n * Copyright(c) 2014-2015 Douglas Christopher Wilson\n * MIT Licensed\n */\n\n\n\n/**\n * Module dependencies.\n * @private\n */\n\nvar createError = require('http-errors')\nvar getBody = require('raw-body')\nvar iconv = require('iconv-lite')\nvar onFinished = require('on-finished')\nvar zlib = require('zlib')\n\n/**\n * Module exports.\n */\n\nmodule.exports = read\n\n/**\n * Read a request into a buffer and parse.\n *\n * @param {object} req\n * @param {object} res\n * @param {function} next\n * @param {function} parse\n * @param {function} debug\n * @param {object} options\n * @private\n */\n\nfunction read (req, res, next, parse, debug, options) {\n  var length\n  var opts = options\n  var stream\n\n  // flag as parsed\n  req._body = true\n\n  // read options\n  var encoding = opts.encoding !== null\n    ? opts.encoding\n    : null\n  var verify = opts.verify\n\n  try {\n    // get the content stream\n    stream = contentstream(req, debug, opts.inflate)\n    length = stream.length\n    stream.length = undefined\n  } catch (err) {\n    return next(err)\n  }\n\n  // set raw-body options\n  opts.length = length\n  opts.encoding = verify\n    ? null\n    : encoding\n\n  // assert charset is supported\n  if (opts.encoding === null && encoding !== null && !iconv.encodingExists(encoding)) {\n    return next(createError(415, 'unsupported charset \"' + encoding.toUpperCase() + '\"', {\n      charset: encoding.toLowerCase(),\n      type: 'charset.unsupported'\n    }))\n  }\n\n  // read body\n  debug('read body')\n  getBody(stream, opts, function (error, body) {\n    if (error) {\n      var _error\n\n      if (error.type === 'encoding.unsupported') {\n        // echo back charset\n        _error = createError(415, 'unsupported charset \"' + encoding.toUpperCase() + '\"', {\n          charset: encoding.toLowerCase(),\n          type: 'charset.unsupported'\n        })\n      } else {\n        // set status code on error\n        _error = createError(400, error)\n      }\n\n      // read off entire request\n      stream.resume()\n      onFinished(req, function onfinished () {\n        next(createError(400, _error))\n      })\n      return\n    }\n\n    // verify\n    if (verify) {\n      try {\n        debug('verify body')\n        verify(req, res, body, encoding)\n      } catch (err) {\n        next(createError(403, err, {\n          body: body,\n          type: err.type || 'entity.verify.failed'\n        }))\n        return\n      }\n    }\n\n    // parse\n    var str = body\n    try {\n      debug('parse body')\n      str = typeof body !== 'string' && encoding !== null\n        ? iconv.decode(body, encoding)\n        : body\n      req.body = parse(str)\n    } catch (err) {\n      next(createError(400, err, {\n        body: str,\n        type: err.type || 'entity.parse.failed'\n      }))\n      return\n    }\n\n    next()\n  })\n}\n\n/**\n * Get the content stream of the request.\n *\n * @param {object} req\n * @param {function} debug\n * @param {boolean} [inflate=true]\n * @return {object}\n * @api private\n */\n\nfunction contentstream (req, debug, inflate) {\n  var encoding = (req.headers['content-encoding'] || 'identity').toLowerCase()\n  var length = req.headers['content-length']\n  var stream\n\n  debug('content-encoding \"%s\"', encoding)\n\n  if (inflate === false && encoding !== 'identity') {\n    throw createError(415, 'content encoding unsupported', {\n      encoding: encoding,\n      type: 'encoding.unsupported'\n    })\n  }\n\n  switch (encoding) {\n    case 'deflate':\n      stream = zlib.createInflate()\n      debug('inflate body')\n      req.pipe(stream)\n      break\n    case 'gzip':\n      stream = zlib.createGunzip()\n      debug('gunzip body')\n      req.pipe(stream)\n      break\n    case 'identity':\n      stream = req\n      stream.length = length\n      break\n    default:\n      throw createError(415, 'unsupported content encoding \"' + encoding + '\"', {\n        encoding: encoding,\n        type: 'encoding.unsupported'\n      })\n  }\n\n  return stream\n}\n","/*!\n * body-parser\n * Copyright(c) 2014-2015 Douglas Christopher Wilson\n * MIT Licensed\n */\n\n\n\n/**\n * Module dependencies.\n */\n\nvar bytes = require('bytes')\nvar debug = require('debug')('body-parser:raw')\nvar read = require('../read')\nvar typeis = require('type-is')\n\n/**\n * Module exports.\n */\n\nmodule.exports = raw\n\n/**\n * Create a middleware to parse raw bodies.\n *\n * @param {object} [options]\n * @return {function}\n * @api public\n */\n\nfunction raw (options) {\n  var opts = options || {}\n\n  var inflate = opts.inflate !== false\n  var limit = typeof opts.limit !== 'number'\n    ? bytes.parse(opts.limit || '100kb')\n    : opts.limit\n  var type = opts.type || 'application/octet-stream'\n  var verify = opts.verify || false\n\n  if (verify !== false && typeof verify !== 'function') {\n    throw new TypeError('option verify must be function')\n  }\n\n  // create the appropriate type checking function\n  var shouldParse = typeof type !== 'function'\n    ? typeChecker(type)\n    : type\n\n  function parse (buf) {\n    return buf\n  }\n\n  return function rawParser (req, res, next) {\n    if (req._body) {\n      debug('body already parsed')\n      next()\n      return\n    }\n\n    req.body = req.body || {}\n\n    // skip requests without bodies\n    if (!typeis.hasBody(req)) {\n      debug('skip empty body')\n      next()\n      return\n    }\n\n    debug('content-type %j', req.headers['content-type'])\n\n    // determine if request should be parsed\n    if (!shouldParse(req)) {\n      debug('skip parsing')\n      next()\n      return\n    }\n\n    // read\n    read(req, res, next, parse, debug, {\n      encoding: null,\n      inflate: inflate,\n      limit: limit,\n      verify: verify\n    })\n  }\n}\n\n/**\n * Get the simple type checker.\n *\n * @param {string} type\n * @return {function}\n */\n\nfunction typeChecker (type) {\n  return function checkType (req) {\n    return Boolean(typeis(req, type))\n  }\n}\n","/*!\n * body-parser\n * Copyright(c) 2014-2015 Douglas Christopher Wilson\n * MIT Licensed\n */\n\n\n\n/**\n * Module dependencies.\n */\n\nvar bytes = require('bytes')\nvar contentType = require('content-type')\nvar debug = require('debug')('body-parser:text')\nvar read = require('../read')\nvar typeis = require('type-is')\n\n/**\n * Module exports.\n */\n\nmodule.exports = text\n\n/**\n * Create a middleware to parse text bodies.\n *\n * @param {object} [options]\n * @return {function}\n * @api public\n */\n\nfunction text (options) {\n  var opts = options || {}\n\n  var defaultCharset = opts.defaultCharset || 'utf-8'\n  var inflate = opts.inflate !== false\n  var limit = typeof opts.limit !== 'number'\n    ? bytes.parse(opts.limit || '100kb')\n    : opts.limit\n  var type = opts.type || 'text/plain'\n  var verify = opts.verify || false\n\n  if (verify !== false && typeof verify !== 'function') {\n    throw new TypeError('option verify must be function')\n  }\n\n  // create the appropriate type checking function\n  var shouldParse = typeof type !== 'function'\n    ? typeChecker(type)\n    : type\n\n  function parse (buf) {\n    return buf\n  }\n\n  return function textParser (req, res, next) {\n    if (req._body) {\n      debug('body already parsed')\n      next()\n      return\n    }\n\n    req.body = req.body || {}\n\n    // skip requests without bodies\n    if (!typeis.hasBody(req)) {\n      debug('skip empty body')\n      next()\n      return\n    }\n\n    debug('content-type %j', req.headers['content-type'])\n\n    // determine if request should be parsed\n    if (!shouldParse(req)) {\n      debug('skip parsing')\n      next()\n      return\n    }\n\n    // get charset\n    var charset = getCharset(req) || defaultCharset\n\n    // read\n    read(req, res, next, parse, debug, {\n      encoding: charset,\n      inflate: inflate,\n      limit: limit,\n      verify: verify\n    })\n  }\n}\n\n/**\n * Get the charset of a request.\n *\n * @param {object} req\n * @api private\n */\n\nfunction getCharset (req) {\n  try {\n    return (contentType.parse(req).parameters.charset || '').toLowerCase()\n  } catch (e) {\n    return undefined\n  }\n}\n\n/**\n * Get the simple type checker.\n *\n * @param {string} type\n * @return {function}\n */\n\nfunction typeChecker (type) {\n  return function checkType (req) {\n    return Boolean(typeis(req, type))\n  }\n}\n","/*!\n * body-parser\n * Copyright(c) 2014 Jonathan Ong\n * Copyright(c) 2014-2015 Douglas Christopher Wilson\n * MIT Licensed\n */\n\n\n\n/**\n * Module dependencies.\n * @private\n */\n\nvar bytes = require('bytes')\nvar contentType = require('content-type')\nvar createError = require('http-errors')\nvar debug = require('debug')('body-parser:urlencoded')\nvar deprecate = require('depd')('body-parser')\nvar read = require('../read')\nvar typeis = require('type-is')\n\n/**\n * Module exports.\n */\n\nmodule.exports = urlencoded\n\n/**\n * Cache of parser modules.\n */\n\nvar parsers = Object.create(null)\n\n/**\n * Create a middleware to parse urlencoded bodies.\n *\n * @param {object} [options]\n * @return {function}\n * @public\n */\n\nfunction urlencoded (options) {\n  var opts = options || {}\n\n  // notice because option default will flip in next major\n  if (opts.extended === undefined) {\n    deprecate('undefined extended: provide extended option')\n  }\n\n  var extended = opts.extended !== false\n  var inflate = opts.inflate !== false\n  var limit = typeof opts.limit !== 'number'\n    ? bytes.parse(opts.limit || '100kb')\n    : opts.limit\n  var type = opts.type || 'application/x-www-form-urlencoded'\n  var verify = opts.verify || false\n\n  if (verify !== false && typeof verify !== 'function') {\n    throw new TypeError('option verify must be function')\n  }\n\n  // create the appropriate query parser\n  var queryparse = extended\n    ? extendedparser(opts)\n    : simpleparser(opts)\n\n  // create the appropriate type checking function\n  var shouldParse = typeof type !== 'function'\n    ? typeChecker(type)\n    : type\n\n  function parse (body) {\n    return body.length\n      ? queryparse(body)\n      : {}\n  }\n\n  return function urlencodedParser (req, res, next) {\n    if (req._body) {\n      debug('body already parsed')\n      next()\n      return\n    }\n\n    req.body = req.body || {}\n\n    // skip requests without bodies\n    if (!typeis.hasBody(req)) {\n      debug('skip empty body')\n      next()\n      return\n    }\n\n    debug('content-type %j', req.headers['content-type'])\n\n    // determine if request should be parsed\n    if (!shouldParse(req)) {\n      debug('skip parsing')\n      next()\n      return\n    }\n\n    // assert charset\n    var charset = getCharset(req) || 'utf-8'\n    if (charset !== 'utf-8') {\n      debug('invalid charset')\n      next(createError(415, 'unsupported charset \"' + charset.toUpperCase() + '\"', {\n        charset: charset,\n        type: 'charset.unsupported'\n      }))\n      return\n    }\n\n    // read\n    read(req, res, next, parse, debug, {\n      debug: debug,\n      encoding: charset,\n      inflate: inflate,\n      limit: limit,\n      verify: verify\n    })\n  }\n}\n\n/**\n * Get the extended query parser.\n *\n * @param {object} options\n */\n\nfunction extendedparser (options) {\n  var parameterLimit = options.parameterLimit !== undefined\n    ? options.parameterLimit\n    : 1000\n  var parse = parser('qs')\n\n  if (isNaN(parameterLimit) || parameterLimit < 1) {\n    throw new TypeError('option parameterLimit must be a positive number')\n  }\n\n  if (isFinite(parameterLimit)) {\n    parameterLimit = parameterLimit | 0\n  }\n\n  return function queryparse (body) {\n    var paramCount = parameterCount(body, parameterLimit)\n\n    if (paramCount === undefined) {\n      debug('too many parameters')\n      throw createError(413, 'too many parameters', {\n        type: 'parameters.too.many'\n      })\n    }\n\n    var arrayLimit = Math.max(100, paramCount)\n\n    debug('parse extended urlencoding')\n    return parse(body, {\n      allowPrototypes: true,\n      arrayLimit: arrayLimit,\n      depth: Infinity,\n      parameterLimit: parameterLimit\n    })\n  }\n}\n\n/**\n * Get the charset of a request.\n *\n * @param {object} req\n * @api private\n */\n\nfunction getCharset (req) {\n  try {\n    return (contentType.parse(req).parameters.charset || '').toLowerCase()\n  } catch (e) {\n    return undefined\n  }\n}\n\n/**\n * Count the number of parameters, stopping once limit reached\n *\n * @param {string} body\n * @param {number} limit\n * @api private\n */\n\nfunction parameterCount (body, limit) {\n  var count = 0\n  var index = 0\n\n  while ((index = body.indexOf('&', index)) !== -1) {\n    count++\n    index++\n\n    if (count === limit) {\n      return undefined\n    }\n  }\n\n  return count\n}\n\n/**\n * Get parser for module name dynamically.\n *\n * @param {string} name\n * @return {function}\n * @api private\n */\n\nfunction parser (name) {\n  var mod = parsers[name]\n\n  if (mod !== undefined) {\n    return mod.parse\n  }\n\n  // this uses a switch for static require analysis\n  switch (name) {\n    case 'qs':\n      mod = require('qs')\n      break\n    case 'querystring':\n      mod = require('querystring')\n      break\n  }\n\n  // store to prevent invoking require()\n  parsers[name] = mod\n\n  return mod.parse\n}\n\n/**\n * Get the simple query parser.\n *\n * @param {object} options\n */\n\nfunction simpleparser (options) {\n  var parameterLimit = options.parameterLimit !== undefined\n    ? options.parameterLimit\n    : 1000\n  var parse = parser('querystring')\n\n  if (isNaN(parameterLimit) || parameterLimit < 1) {\n    throw new TypeError('option parameterLimit must be a positive number')\n  }\n\n  if (isFinite(parameterLimit)) {\n    parameterLimit = parameterLimit | 0\n  }\n\n  return function queryparse (body) {\n    var paramCount = parameterCount(body, parameterLimit)\n\n    if (paramCount === undefined) {\n      debug('too many parameters')\n      throw createError(413, 'too many parameters', {\n        type: 'parameters.too.many'\n      })\n    }\n\n    debug('parse urlencoding')\n    return parse(body, undefined, undefined, {maxKeys: parameterLimit})\n  }\n}\n\n/**\n * Get the simple type checker.\n *\n * @param {string} type\n * @return {function}\n */\n\nfunction typeChecker (type) {\n  return function checkType (req) {\n    return Boolean(typeis(req, type))\n  }\n}\n"]}